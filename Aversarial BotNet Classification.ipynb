{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e58ee40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the libraries\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, chi2, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score , confusion_matrix, precision_score, recall_score, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12ce8944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets Loading Process\n",
    "\n",
    "# Dataset 1 : CTU-133 \n",
    "# Dataset 2 : IDS2017\n",
    "# Dataset 3 : CIC-IDS2018 \n",
    "# Dataset 4 : UNB-CA Botnet\n",
    "\n",
    "# In order to have a proper and clean code, i will implement 4 functions, each function when called will \n",
    "# automatically load a dataset, and you can type help( function_name ) to get a description on the desired Dataset\n",
    "# as i will implement a docstring containing the description\n",
    "\n",
    "\n",
    "# You must keep in mind that the Datasets i'm using are extremely huge ( up to 79 GB of data) so until i discover \n",
    "# a way to optimize it, computations will be taking time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c1ed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CTU_13():\n",
    "    '''\n",
    "CTU-13 is a publicly available dataset of botnet traffic generated in a controlled environment. \n",
    "It contains 13 captures of different botnet traffic scenarios, including a mix \n",
    "of normal traffic and botnet traffic.The dataset includes both network traffic data and \n",
    "malware binaries for analysis. CTU-13 is a valuable resource for researchers and practitioners \n",
    "working in the field of network security and provides a realistic simulation of botnet trafficthat\n",
    "can be used to evaluate the effectiveness of different detection and prevention techniques.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3f68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_IDS2017():\n",
    "    '''\n",
    "    IDS2017 is a publicly available dataset of network traffic generated in a realistic environment \n",
    "    to evaluate the performance of intrusion detection systems (IDS). It contains 5 days of network traffic\n",
    "    captured from a real-world network environment, including a mix of normal traffic and various types \n",
    "    of attacks, such as botnet, DDoS, and brute-force attacks. The dataset includes both raw network traffic \n",
    "    data and preprocessed flow data, making it suitable for various types of IDS research. IDS2017 provides \n",
    "    a valuable resource for researchers and practitioners to evaluate and compare the effectiveness of\n",
    "    different IDS techniques in detecting and mitigating various types of attacks.\n",
    "        '''\n",
    "    # we will start by loading the first file of our second dataset just to test \n",
    "    \n",
    "    # Load the CSV file into a pandas DataFrame object\n",
    "    df_IDS2017 = pd.read_csv('../Datasets/IDS_2017/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')\n",
    "    \n",
    "    # Print the first 5 rows of the DataFrame\n",
    "    print(df_IDS2017.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f69e4c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225745, 79)\n"
     ]
    }
   ],
   "source": [
    "load_IDS2017()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef2ad19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2830743, 79)\n"
     ]
    }
   ],
   "source": [
    "# Quick test to concatenate all the ID2017 csvs into one dataframe \n",
    "\n",
    "# Set the directory where your CSV files are located\n",
    "directory = '../Datasets/IDS_2017'\n",
    "\n",
    "# Create an empty list to store your DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Loop over all CSV files in the directory and read them into separate DataFrames\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        df_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Print the first 5 rows of the combined DataFrame\n",
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2736bf",
   "metadata": {},
   "source": [
    "# Task Done With success 1 file's shape is  (225745, 79), while concatenated files are (2830743, 79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27cd49e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CIC_IDS2018 ():\n",
    "    '''\n",
    "CIC-IDS2018 is a publicly available dataset of network traffic generated in a realistic environment \n",
    "to evaluate the performance of intrusion detection systems (IDS). It contains 9 days of network traffic\n",
    "captured from a real-world network environment, including a mix of normal traffic and various types of \n",
    "attacks, such as botnet, DDoS, and malware attacks. The dataset includes both raw network traffic data \n",
    "and preprocessed flow data, making it suitable for various types of IDS research. CIC-IDS2018 provides \n",
    "a valuable resource for researchers and practitioners to evaluate and compare the effectiveness of different \n",
    "IDS techniques in detecting and mitigating various types of attacks in a realistic and complex \n",
    "network environment.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00dcd16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_UNB_CA_Botnet():\n",
    "    '''\n",
    "UNB-CA Botnet is a publicly available dataset of network traffic generated in a controlled environment \n",
    "to evaluate the effectiveness of different detection and prevention techniques against botnet attacks. \n",
    "The dataset contains traffic captures from different botnet scenarios, including HTTP, DNS, and P2P botnets,\n",
    "as well as normal traffic. The dataset includes both raw network traffic data and preprocessed flow data, \n",
    "making it suitable for various types of botnet research. UNB-CA Botnet provides a valuable resource \n",
    "for researchers and practitioners to develop and evaluate new botnet detection and prevention techniques\n",
    "in a controlled environment, allowing for better understanding and mitigation of botnet attacks.\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
